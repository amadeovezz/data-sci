{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2.0x + 0.5y + 0 = 0\n",
      "Classifier theta: [-2.   0.5], classifier offset: 0 \n",
      "\n",
      "iterations_of_training_data: 5\n",
      "converged: True\n",
      "training_iterations_until_convergence: 2\n",
      "total_errors: 2\n",
      "thetas: [array([-1, -1]), array([-2. ,  0.5])]\n",
      "times_features_are_misclassified: {'[-1 -1]': 1, '[1 0]': 0, '[-1.   1.5]': 1}\n",
      "\n",
      "Errors returned by classifier: 0.0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ml.classifiers import search, validate\n",
    "from ml.loss import loss_funcs\n",
    "\n",
    "data = [\n",
    "     [np.array([-1, -1]), 1]\n",
    "    , [np.array([1, 0]), -1]\n",
    "    , [np.array([-1, 1.5]), 1]\n",
    "]\n",
    "\n",
    "# Run the perception algorithm and generate a classifier\n",
    "training_data = pd.DataFrame(data, columns=['features', 'label'])\n",
    "logging.basicConfig(format='%(message)',level=logging.ERROR)\n",
    "\n",
    "results = search.perceptron(training_data, 5, include_offset=False)\n",
    "classifier = results['classifier']\n",
    "\n",
    "# Classifier\n",
    "print(classifier)\n",
    "print(f'Classifier theta: {classifier.theta}, classifier offset: {classifier.offset} \\n')\n",
    "\n",
    "# Summary results\n",
    "summary = results['summary']\n",
    "for k, values in summary.items():\n",
    "    print(f'{k}: {values}')\n",
    "\n",
    "# Check for training errors\n",
    "errors = validate.training_errors(training_data,classifier)\n",
    "print(f'\\nErrors returned by classifier: {errors}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum error found from candidate thetas: 0.0499999999999999, Thetas: (-2.2,-0.8999999999999999)\n",
      "\n",
      "Number of classified errors: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ml.classifiers import models\n",
    "# Brute force theta search\n",
    "\n",
    "# Create a ton of candidate thetas (models) with a 1x2 array\n",
    "candidate_thetas = np.mgrid[-3:3:.1, -3:3:.1].reshape(2,-1).T\n",
    "results = []\n",
    "\n",
    "# For each candidate theta see what the total average loss is through an iteration of training data\n",
    "for theta in candidate_thetas:\n",
    "    output = validate.average_loss(training_data,theta,loss_func=loss_funcs.hinge_loss)\n",
    "    results.append([theta[0],theta[1],output])\n",
    "\n",
    "# Parse results\n",
    "total_loss = np.array([result[2] for result in results])\n",
    "\n",
    "# Find min via indexing\n",
    "index_min = np.argmin(total_loss[np.nonzero(total_loss)])\n",
    "normal_x, normal_y, min = results[index_min]\n",
    "print(f'Minimum error found from candidate thetas: {min}, Thetas: ({normal_x},{normal_y})\\n')\n",
    "\n",
    "# Test classifier with values\n",
    "objective_classifier = models.LinearClassifier(theta=np.array((normal_x,normal_y)))\n",
    "errors = validate.training_errors(training_data,objective_classifier)\n",
    "print(f'Number of classified errors: {errors}')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data = [\n",
    "    [np.array([-1, -1]), 1]\n",
    "    , [np.array([1, 0]), -1]\n",
    "    , [np.array([-1, 1.5]), 1]\n",
    "]\n",
    "\n",
    "# Run the perception algorithm and generate a classifier\n",
    "training_data = pd.DataFrame(data, columns=['features', 'label'])\n",
    "logging.basicConfig(format='%(message)',level=logging.ERROR)\n",
    "\n",
    "#results = search.gradient_descent(training_data, 5, include_offset=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}